{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =  8\n",
    "rng = np.random.default_rng(seed=0)\n",
    "df = pd.DataFrame(np.around(rng.random((n, 4)), 1), columns=['a','b','c','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The way the model will go through the values of the df\n",
    "OUT_STEPS = 2  \n",
    "input_width = 2   # Take two rows (or time steps) of all columns as input\n",
    "label_width = OUT_STEPS  # Size of the prediction (output)\n",
    "shift = OUT_STEPS  # Time (or rows) offset between input and output\n",
    "total_window_size = input_width + shift\n",
    "batch_size = 1\n",
    "label_index = None #In the future will be the index of 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a sort of conversion from an array to an tf._.EagerTensor\n",
    "data = np.array(df.values, dtype=np.float32)\n",
    "def stack_data(data, total_window_size):\n",
    "    batches = []\n",
    "    start = 0\n",
    "    end = total_window_size\n",
    "    for start in range(data.shape[0]-1):\n",
    "        batch = data[start:end]\n",
    "        start = start + total_window_size + 1\n",
    "        end = start\n",
    "        if batch.shape[0] == total_window_size:\n",
    "            batches.append(batch)\n",
    "    return tf.stack(batches)\n",
    "stacked_data = stack_data(data, total_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to calculate a baseline model. In this case, a model that averages the last values of the input, and repeats it OUT_STEPS times in the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepMeanBaseline(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A mixture of MultiStepLastBaseline & RepeatBaseline in the link below \n",
    "    but calculating the average instead of returning the last value.\n",
    "    https://www.tensorflow.org/tutorials/structured_data/time_series#baselines\n",
    "    \"\"\"\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        \"\"\"\n",
    "        Calls the model on new inputs.\n",
    "        Returns the outputs as tensors.\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/Model#call\n",
    "        \"\"\"\n",
    "        # inputs.shape: (None, 2, 4) (batch, time_steps <rows>, features <columns>)\n",
    "        # type(inputs): <class 'tensorflow.python.framework.ops.Tensor'>\n",
    "\n",
    "        if self.label_index is None:\n",
    "            # How can I grab each input & average the values along the time?\n",
    "            average_time_dim = inputs[:, np.mean(:), :] # SYNTAXERROR\n",
    "            # possible shape of average_time_dim: (4,)\n",
    "            average_reshaped = average_time_dim[tf.newaxis, tf.newaxis, :]\n",
    "            return tf.tile(average_reshaped, [1, self.out_steps, 1])\n",
    "        # TODO.\n",
    "        # result = inputs[:, :, self.label_index]\n",
    "        # return result[:, :, tf.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the tutorial, the data is splitted into inputs and outputs with a function similar to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_slice = slice(0, input_width)\n",
    "label_slice = slice(total_window_size-label_width, None)\n",
    "def split_stacked_data(stacked_data):\n",
    "    \"\"\"\n",
    "    Split dataset into inputs and labels (or targets)\n",
    "    https://www.tensorflow.org/tutorials/structured_data/time_series#2_split\n",
    "    \"\"\"\n",
    "    inputs = stacked_data[:,input_slice, :] \n",
    "    labels = stacked_data[:,label_slice,label_index:] \n",
    "    inputs.set_shape([None, input_width, None])\n",
    "    labels.set_shape([None, label_width, None])\n",
    "    return inputs, labels\n",
    "# inputs, labels = split_stacked_data(stacked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, the dataset is created, also, the split function is mapped to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array\n",
    "input_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=data,              # all columns of the df from 1st to penultimate rows\n",
    "    targets=None,           # To deliver a single dataset\n",
    "    sequence_length=total_window_size,   # Yields 1 step per batch in the (input) data\n",
    "    sequence_stride=1,                  # Shifts 1 step for next batches\n",
    "    shuffle=False,      \n",
    "    batch_size=batch_size  # Works only with 1 but the loss & error are the same as in the timeseries tutorial\n",
    "    )\n",
    "input_dataset = input_dataset.map(split_stacked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset has inputs of shape `(batch_zise, input_width, df.shape[1])` and the outputs have a shape of `(batch_size, OUT_STEPS, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [[[0.6 0.3 0.  0. ]\n",
      "  [0.8 0.9 0.6 0.7]]]\n",
      "target: [[[0.5 0.9 0.8 0. ]\n",
      "  [0.9 0.  0.7 0.2]]]\n",
      "input: [[[0.8 0.9 0.6 0.7]\n",
      "  [0.5 0.9 0.8 0. ]]]\n",
      "target: [[[0.9 0.  0.7 0.2]\n",
      "  [0.9 0.5 0.3 0.4]]]\n",
      "input.shape: (1, 2, 4)\n",
      "target.shape: (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "for batch in input_dataset.take(2):\n",
    "    input, target = batch\n",
    "    print(f'input: {input}')\n",
    "    print(f'target: {target}')\n",
    "print(f'input.shape: {input.shape}')\n",
    "print(f'target.shape: {target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2344999760389328, 0.39500001072883606]\n"
     ]
    }
   ],
   "source": [
    "# Baseline from WindowGenerator\n",
    "baseline_model = RepeatBaseline()\n",
    "baseline_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()]) # MAE\n",
    "# Evaluation from WindowGenerator\n",
    "evaluation = baseline_model.evaluate(input_dataset, verbose=0)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.6, 0.3, 0. , 0. ],\n",
       "        [0.8, 0.9, 0.6, 0.7]],\n",
       "\n",
       "       [[0.8, 0.9, 0.6, 0.7],\n",
       "        [0.5, 0.9, 0.8, 0. ]],\n",
       "\n",
       "       [[0.5, 0.9, 0.8, 0. ],\n",
       "        [0.9, 0. , 0.7, 0.2]],\n",
       "\n",
       "       [[0.9, 0. , 0.7, 0.2],\n",
       "        [0.9, 0.5, 0.3, 0.4]],\n",
       "\n",
       "       [[0.9, 0.5, 0.3, 0.4],\n",
       "        [0. , 0.1, 0.7, 0.6]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.predict(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[[0.7, 0.6, 0.3, 0.35],\n",
    "#         [0.7, 0.6, 0.3, 0.35]],\n",
    "\n",
    "#        [[0.65, 0.9, 0.7, 0.35],\n",
    "#         [0.65, 0.9, 0.7, 0.35]],\n",
    "\n",
    "#        [[0.7, 0.45, 0.75, 0.1],\n",
    "#         [0.7, 0.45, 0.75, 0.1]],\n",
    "# ...                           ]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
