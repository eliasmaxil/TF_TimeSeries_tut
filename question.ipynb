{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow. call() method to create a baseline model which averages the \"inputs\" with type  framework.ops.Tensor for timeseries data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, I have been following the \"[Time series forecasting](https://www.tensorflow.org/tutorials/structured_data/time_series)\" tutorial and I have some troubles making an own multi-step baseline model that can average the input data in the time axis, and repeat it as the target values in the modelâ€™s prediction.\n",
    "\n",
    "In the link above, the authors of the tutorial use simple baselines such as the code below, to take the last time element of the input and tile (or repeat) it `OUT_STEPS` times. \n",
    " \n",
    "```python\n",
    "class MultiStepLastBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
    "```\n",
    "\n",
    "Or a baseline that just repeats the same values of the data in the past, according to the number of steps stated in the `window` of data (`input_width`) of the model. \n",
    "\n",
    "```python\n",
    "class RepeatBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return inputs\n",
    "```\n",
    "\n",
    "I would like to take all the elements of the `inputs` and apply a simple average to them before `tf.tile` them. Basically apply an average to RepeatBaseline` and repeat the average as in `MultiStepLastBaseline`.\n",
    "\n",
    "The minimal code to produce a tf.Dataset that can be replicated with the code in the tutorial (https://www.tensorflow.org/tutorials/structured_data/time_series) is the following:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "n =  8\n",
    "rng = np.random.default_rng(seed=0)\n",
    "df = pd.DataFrame(np.around(rng.random((n, 4)), 1), columns=['a','b','c','y'])\n",
    "```\n",
    "\n",
    "In the tutorial, the data is managed by a `window` of consecutive samples from the data, which can be emulated with:\n",
    "\n",
    "```python\n",
    "# Settings of what a window object would have\n",
    "OUT_STEPS = 2  \n",
    "input_width = 2   # Take two rows (or time steps) of all columns as input\n",
    "label_width = OUT_STEPS  # Size of the prediction (output)\n",
    "shift = OUT_STEPS  # Time (or rows) offset between input and output\n",
    "total_window_size = input_width + shift\n",
    "batch_size = 1\n",
    "label_index = None #In the future will be the index of 'y'\n",
    "\n",
    "# Just a conversion of the df to an tf._.EagerTensor\n",
    "data = np.array(df.values, dtype=np.float32)\n",
    "def stack_data(data, total_window_size):\n",
    "    batches = []\n",
    "    start = 0\n",
    "    end = total_window_size\n",
    "    for start in range(data.shape[0]-1):\n",
    "        batch = data[start:end]\n",
    "        start = start + total_window_size + 1\n",
    "        end = start\n",
    "        if batch.shape[0] == total_window_size:\n",
    "            batches.append(batch)\n",
    "    return tf.stack(batches)\n",
    "\n",
    "stacked_data = stack_data(data, total_window_size)\n",
    "```\n",
    "\n",
    "Further, the data is manipulated and transformed into a `dataset`. The minimal code is\n",
    "\n",
    "```python\n",
    "input_slice = slice(0, input_width)\n",
    "label_slice = slice(total_window_size-label_width, None)\n",
    "def split_stacked_data(stacked_data):\n",
    "    \"\"\"\n",
    "    Split dataset into inputs and labels (or targets)\n",
    "    https://www.tensorflow.org/tutorials/structured_data/time_series#2_split\n",
    "    \"\"\"\n",
    "    inputs = stacked_data[:,input_slice, :] \n",
    "    labels = stacked_data[:,label_slice,label_index:] \n",
    "    inputs.set_shape([None, input_width, None])\n",
    "    labels.set_shape([None, label_width, None])\n",
    "    return inputs, labels\n",
    "# inputs, labels = split_stacked_data(stacked_data)\n",
    "\n",
    "input_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data, targets=None, sequence_length=total_window_size,  \n",
    "        sequence_stride=1, shuffle=False, batch_size=batch_size)\n",
    "input_dataset = input_dataset.map(split_stacked_data)\n",
    "```\n",
    "\n",
    "So far, in the `MyAverageBaseline` model, I have succeeded to pass the `inputs` through a `Dense` model and make an `Average` of the data. Since the `df` has four features, a similar number of units are declared in de `Dense`. However, the results are not what I expect to get. \n",
    "\n",
    "```python\n",
    "class MyAverageBaseline(tf.keras.Model):\n",
    "    def __init__(self, out_steps, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "        self.out_steps = out_steps\n",
    "        self.a_model = tf.keras.layers.Dense(4, activation=tf.nn.relu, trainable=False)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        # type(inputs): <class 'tensorflow.python.framework.ops.Tensor'>\n",
    "        if self.label_index is None:\n",
    "            # How can I grab each input & average the values along the time?\n",
    "\n",
    "            # Working but not delivering the results\n",
    "            x = self.a_model(inputs)\n",
    "            result = tf.keras.layers.Average()([x])\n",
    "            \n",
    "            # The **pseudocode** where each inputs is averaged in time dimension\n",
    "            # average_time_dim = inputs[:, np.mean(:, axis=0), :] # SyntaxError\n",
    "            # possible shape of average_time_dim: (4,)\n",
    "            # average_reshaped = average_time_dim[tf.newaxis, tf.newaxis, :]\n",
    "            # return tf.tile(average_reshaped, [1, self.out_steps, 1])\n",
    "\n",
    "            return result\n",
    "\n",
    "        # TODO. I would just have to pick a part of the resul\n",
    "        # result = inputs[:, :, self.label_index]\n",
    "        # return result[:, :, tf.newaxis]\n",
    "```\n",
    "\n",
    "In the **pseudocode**, `def call():` would calculate the average of the `inputs` along the time axis and then `tf.tile` the average `OUT_STEPS` times.  \n",
    "  \n",
    "I also have tried with `tf.mean_reduce()` and `tf.mean()` but I guess I am new in Tensorflow to make a calculation working inside an iterator.  \n",
    "  \n",
    "The **desired results** should be that once I compile and evaluate the baseline model. \n",
    "\n",
    "```python\n",
    "baseline_model = MyAverageBaseline()\n",
    "baseline_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "evaluation = baseline_model.evaluate(input_dataset, verbose=2)\n",
    "predictions = baseline_model.predict(input_dataset)\n",
    "```\n",
    "\n",
    "The predicted values would be the same as the results below, taking into account that `seed=0` to generate the random `df`.  \n",
    "\n",
    "```bash\n",
    ">>> print(predictions) \n",
    ">>> array([[[0.7, 0.6, 0.3, 0.35],\n",
    "        [0.7, 0.6, 0.3, 0.35]],\n",
    "\n",
    "        [[0.65, 0.9, 0.7, 0.35],\n",
    "        [0.65, 0.9, 0.7, 0.35]],\n",
    "\n",
    "        ...  More data here  ]])\n",
    "```\n",
    "\n",
    "Could somebody help me to figure out the code that the `def call(self, inputs):` method should include in the `class MyAverageBaseline(tf.keras.Model):`? Thank you.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
